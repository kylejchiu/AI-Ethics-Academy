<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Bias in the Real World | AI Ethics Academy</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="common.css">
  <style>
    :root {
      --teal: #00bfa6;
      --teal-dark: #009e8a;
      --bg-light: #f8f9fa;
      --bg-dark: #121212;
      --text-light: #1a1a1a;
      --text-dark: #f1f1f1;
    }
    body {
      font-family: 'Inter', sans-serif;
      background: var(--bg-light);
      color: var(--text-light);
      margin: 0;
      padding: 0;
      transition: background 0.3s, color 0.3s;
    }
    body.dark { background: var(--bg-dark); color: var(--text-dark); }

    main {
      max-width: 950px;
      margin: 7rem auto 2rem;
      padding: 1rem;
    }
    h2 { color: var(--teal-dark); }
    .fact-wheel-container { text-align: center; margin-bottom: 3rem; }
    #wheel { position: relative; display: inline-block; }
    #wheelCanvas {
      border-radius: 50%;
      border: 6px solid var(--teal);
      background: white;
      transition: transform 3s cubic-bezier(0.25, 1, 0.5, 1);
    }
    #wheel-center {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: var(--teal);
      color: white;
      border-radius: 50%;
      width: 100px;
      height: 100px;
      line-height: 100px;
      font-weight: 700;
      font-size: 1.1rem;
      cursor: pointer;
    }
    #wheel-center:hover { background: var(--teal-dark); }
    .fact-of-day {
      text-align: center;
      background: var(--teal);
      color: white;
      padding: 0.8rem;
      border-radius: 10px;
      margin-bottom: 2rem;
      font-weight: 600;
    }
    .case-study {
      background: white;
      color: var(--text-light);
      border-radius: 10px;
      box-shadow: 0 3px 10px rgba(0,0,0,0.1);
      margin-bottom: 1.5rem;
      padding: 1.5rem;
      transition: transform 0.2s;
    }
    .case-study:hover { transform: translateY(-3px); }
    body.dark .case-study { background: #1e1e1e; color: var(--text-dark); }
    .read-more {
      display: inline-block;
      margin-top: 0.5rem;
      color: var(--teal-dark);
      text-decoration: none;
      font-weight: 600;
    }
    .read-more:hover { text-decoration: underline; }
  </style>
</head>
<body>

<header>
  <div class="brand">
    <img class="logo" src="https://online.uc.edu/wp-content/uploads/2024/08/What-Is-AI-Featured.jpg" alt="AI Ethics Academy Logo">
    <h1>AI Ethics Academy</h1>
  </div>
  <nav>
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="learn.html">Learn</a></li>
      <li><a href="quiz.html">Quiz</a></li>
      <li><a href="sandbox.html">Sandbox</a></li>
      <li><a href="read.html" aria-current="page">Read</a></li>
      <li><a href="teach.html">Teach</a></li>
      <li><a href="chat.html">Chat</a></li>
    </ul>
  </nav>
  <div style="display:flex;gap:.5rem;align-items:center">
    <button id="theme-toggle">Dark Mode</button>
  </div>
</header>

<main>
  <div class="fact-of-day" id="fact-of-day">Loading Fact of the Day...</div>

  <section class="fact-wheel-container">
    <h2>Spin the AI Ethics Fact Wheel</h2>
    <div class="wheel-wrapper">
      <div id="wheel">
        <canvas id="wheelCanvas" width="320" height="320"></canvas>
        <div id="wheel-center">SPIN</div>
      </div>
    </div>
    <p id="selected-fact" style="margin-top:1rem;font-weight:600;"></p>
  </section>

  <section>
    <h2>Case Studies: AI Bias in the Real World</h2>

    <div class="case-study">
      <h3>Amazon’s Biased Hiring Algorithm</h3>
      <p>In 2018, Amazon scrapped its AI hiring tool after discovering it discriminated against women...</p>
      <a class="read-more" href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G" target="_blank">Read more →</a>
    </div>

    <div class="case-study">
      <h3>COMPAS and Criminal Justice Bias</h3>
      <p>ProPublica’s 2016 investigation found that the COMPAS risk assessment tool used in U.S. courts...</p>
      <a class="read-more" href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank">Read more →</a>
    </div>

    <div class="case-study">
      <h3>Facial Recognition and Misidentification</h3>
      <p>Studies by MIT and NIST revealed facial recognition software had significantly higher error rates...</p>
      <a class="read-more" href="https://www.nist.gov/news-events/news/2019/12/nist-study-evaluates-effects-race-age-sex-face-recognition-software" target="_blank">Read more →</a>
    </div>
  </section>
</main>

<script>
(function(){
  const toggleBtn = document.getElementById('theme-toggle');
  const themeKey = 'theme';
  function applyTheme(t){
    if(t === 'dark'){
      document.body.classList.add('dark');
      toggleBtn.textContent = 'Light Mode';
    } else {
      document.body.classList.remove('dark');
      toggleBtn.textContent = 'Dark Mode';
    }
  }
  const saved = localStorage.getItem(themeKey) || 
    (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light');
  applyTheme(saved);
  toggleBtn.addEventListener('click', ()=>{
    const newTheme = document.body.classList.contains('dark') ? 'light' : 'dark';
    applyTheme(newTheme);
    localStorage.setItem(themeKey, newTheme);
  });
})();

const facts = [
  "MIT researchers found facial recognition misidentifies darker-skinned women up to 34% more than lighter-skinned men.",
  "A 2018 AI experiment in China found that facial-recognition software mislabeled 1 in 5 Uyghur individuals as criminals.",
  "Amazon’s AI hiring tool downgraded resumes containing the word 'women’s' due to historical hiring bias.",
  "A health algorithm in the US assigned Black patients lower priority despite similar health needs, because it used cost as a proxy.",
  "AI trained on Reddit data learned to mimic extremist language within hours.",
  "Emotion recognition systems confuse some cultural expressions as negative emotions up to 40% of the time.",
  "AI-driven sentencing tools like COMPAS incorrectly labeled Black defendants as high-risk twice as often as white defendants.",
  "Only 7% of AI papers include datasets and code sufficient for reproducibility.",
  "Twitter’s image cropping AI favored lighter-skinned faces in 2019 testing.",
  "Google’s ad delivery algorithm showed high-paying job ads more often to men than women.",
  "AI in hiring can penalize applicants who took nontraditional career paths, even when equally qualified.",
  "Some AI text generators amplified racial slurs after training on unfiltered social media datasets.",
  "AI-generated music datasets have led to copyright conflicts because models reproduce original works.",
  "AI in medical imaging misdiagnosed skin conditions 50% more frequently on darker skin.",
  "A study of YouTube recommendation algorithms found that they amplify polarizing content faster than neutral content.",
  "AI chatbots like Tay learned offensive language from user interactions within 24 hours.",
  "AI in predicting criminal recidivism has been found to replicate historical policing biases, not reduce them.",
  "Voice recognition systems for smart assistants fail up to 35% of the time for non-native accents.",
  "Deepfake audio can impersonate someone’s voice with as little as 3 seconds of recording.",
  "Bias can creep into AI through camera angles or lighting in datasets, not just labels.",
  "Some generative AI models reproduce training images verbatim, creating unexpected copyright issues.",
  "Autonomous vehicle AI misclassified a pedestrian in dark clothing as a traffic cone during testing.",
  "Algorithms for credit scoring in Brazil unfairly denied loans to rural populations due to historical economic data.",
  "AI models can detect sexual orientation from facial images with higher accuracy than humans, raising privacy concerns.",
  "AI surveillance cameras in schools flagged minority students more often for rule violations.",
  "Predictive policing in Chicago reinforced redlining patterns present in historical crime data.",
  "Some AI image captioning systems describe Black people using negative words more often than white people.",
  "AI algorithms can overfit to rare populations, producing wildly inaccurate predictions for them.",
  "Automated resume filters often reject applicants with non-Western names, even with similar qualifications.",
  "AI-trained chatbots on mental health forums sometimes give harmful advice, highlighting lack of ethical oversight.",
  "Generative text models occasionally fabricate references, citations, or dates entirely.",
  "In 2016, a neural network memorized personal details from its training data, exposing privacy risks.",
  "Some AI-driven hiring tools penalized mothers by detecting maternity-related words.",
  "A US study found that job ads served by AI platforms reached men 18% more than women.",
  "AI in financial trading has occasionally caused market flash crashes due to emergent, unpredicted behavior.",
  "Machine translation AI sometimes erases gender in languages that require it, introducing bias in documents.",
  "AI moderation tools have blocked legitimate minority dialects on social media platforms.",
  "Autonomous drones misidentified farm animals as humans during certain AI vision tests.",
  "A music recommendation AI in Japan accidentally reinforced gender stereotypes by overplaying female artists in certain genres.",
  "Language models can predict personal attributes, like age or political leaning, from a single text sample.",
  "AI-designed molecules sometimes violated chemical safety rules, exposing gaps in automated testing.",
  "Self-driving car AI misclassified a stop sign covered in graffiti as a speed limit sign.",
  "AI in advertising predicted higher interest in luxury goods for men than women, even when controlling for income.",
  "Some AI news recommendation systems amplify misinformation during breaking news events.",
  "Facial-recognition door locks failed disproportionately on users wearing religious headwear.",
  "Emotion AI in hiring misread nervousness as incompetence more often in non-native speakers.",
  "Deepfake detection models often fail on images of darker-skinned individuals.",
  "AI algorithms in China assigned a 'trust score' that heavily penalized political dissenters, showing sociopolitical impact.",
  "Generative AI models can produce realistic celebrity faces without consent, raising ethical concerns.",
  "AI in education has disproportionately marked minority students as low-performing based on biased historical grading data.",
  "Some content recommendation AI predicts user preferences using location data, sometimes revealing sensitive habits.",
  "AI filters on social media flagged disability-related terms as inappropriate content.",
  "AI-driven insurance scoring sometimes penalizes users for their neighborhood instead of individual behavior.",
  "Researchers found that some AI language models can predict a person’s sexual orientation from a single facial image with higher accuracy than humans, raising serious privacy and ethical concerns."
];

window.__FACTS_ARRAY__ = facts;

const dayFact = facts[new Date().getDate() % facts.length];
document.getElementById('fact-of-day').textContent = "Fact of the Day: " + dayFact;

const canvas = document.getElementById('wheelCanvas');
const ctx = canvas.getContext('2d');
const numSegments = facts.length;
const angle = (2 * Math.PI) / numSegments;
const colors = ["#00bfa6", "#009e8a"];

let startAngle = 0;
for (let i = 0; i < numSegments; i++) {
  const endAngle = startAngle + angle;
  ctx.beginPath();
  ctx.moveTo(160, 160);
  ctx.arc(160, 160, 150, startAngle, endAngle);
  ctx.fillStyle = colors[i % 2];
  ctx.fill();
  startAngle = endAngle;
}

let currentRotation = 0;
const spinBtn = document.getElementById('wheel-center');
const selectedFact = document.getElementById('selected-fact');
const wheel = document.getElementById('wheelCanvas');

spinBtn.onclick = () => {
  const spins = Math.floor(Math.random() * 360);
  currentRotation += 1080 + spins;
  wheel.style.transform = `rotate(${currentRotation}deg)`;
  const index = Math.floor((numSegments - ((currentRotation / (360 / numSegments)) % numSegments)) % numSegments);
  setTimeout(() => {
    selectedFact.textContent = "Fact: " + facts[index];
  }, 3000);
};
</script>
</body>
</html>
