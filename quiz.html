<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Quiz | AI Ethics Academy</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="common.css">
  <script src="common.js" defer></script>
  <style>
    .page-title {
      text-align:center;
      color:var(--teal);
      margin-top:1rem;
    }
    #quiz-container {
      max-width:800px;
      margin:2rem auto;
    }
    .quiz-question {
      background:var(--card-light);
      color:var(--text-light);
      border-radius:10px;
      box-shadow:0 3px 10px rgba(0,0,0,0.1);
      padding:1.5rem;
      margin-bottom:1.5rem;
      transition:transform 0.2s;
    }
    body.dark .quiz-question {
      background:#1e1e1e;
      color:var(--text-dark);
    }
    .quiz-question:hover {transform:translateY(-3px);}
    .options {
      list-style:none;
      padding:0;
      margin:1rem 0;
    }
    .options li {
      margin:.4rem 0;
    }
    .options button {
      width:100%;
      background:#f4f8f8;
      color:var(--text-light);
      border:1px solid #ccc;
      border-radius:6px;
      padding:.6rem;
      font-size:1rem;
      cursor:pointer;
      text-align:left;
    }
    .options button:hover {
      background:#e0f5f2;
    }
    body.dark .options button {
      background:#2a3a39;
      color:var(--text-dark);
      border:1px solid #444;
    }
    .correct {background:var(--teal)!important;color:white!important;}
    .incorrect {background:#d9534f!important;color:white!important;}
    .explanation {
      margin-top:.5rem;
      font-style:italic;
      color:var(--teal-dark);
      display:none;
    }
    #result {
      text-align:center;
      margin:2rem auto;
      font-weight:600;
    }
  </style>
</head>
<body>

<header>
  <div class="brand">
    <img class="logo" src="https://online.uc.edu/wp-content/uploads/2024/08/What-Is-AI-Featured.jpg" alt="AI Ethics Academy Logo">
    <h1>AI Ethics Academy</h1>
  </div>
  <nav>
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="learn.html">Learn</a></li>
      <li><a href="quiz.html" aria-current="page">Quiz</a></li>
      <li><a href="sandbox.html">Sandbox</a></li>
      <li><a href="read.html">Read</a></li>
      <li><a href="teach.html">Teach</a></li>
      <li><a href="chat.html">Chat</a></li>
    </ul>
  </nav>
  <div style="display:flex;gap:.5rem;align-items:center">
    <button id="theme-toggle">Dark Mode</button>
  </div>
</header>

<main>
  <section class="card" style="text-align:center;">
    <h2 class="page-title">AI Ethics Quiz</h2>
    <p>Select your answers to see instant feedback for each question.</p>
  </section>

  <section class="card">
    <div id="quiz-container"></div>
    <div id="result"></div>
  </section>
</main>

<script>
    const questionsData = [
  {
    question: "Which ethical principle is most directly violated by biased training data in AI systems?",
    options: ["Autonomy", "Justice", "Beneficence", "Non-maleficence"],
    answer: [1],
    explanation: "Justice relates to fairness and equality, which biased data undermines."
  },
  {
    question: "What is the 'black box' problem in AI ethics?",
    options: [
      "AI systems that crash without warning",
      "AI systems that are too expensive to audit",
      "AI systems whose decision-making processes are opaque",
      "AI systems that use outdated data"
    ],
    answer: [2],
    explanation: "The 'black box' problem refers to the lack of transparency in how AI systems make decisions."
  },
  {
    question: "Which of the following best describes 'algorithmic opacity'?",
    options: [
      "The use of encryption in AI systems",
      "The inability to understand how an AI system reached a decision",
      "The failure of AI systems to update in real time",
      "The use of proprietary code in open-source projects"
    ],
    answer: [1],
    explanation: "Algorithmic opacity refers to the lack of interpretability in AI decision-making."
  },
  {
    question: "Which concept refers to the right of individuals to control how their personal data is used by AI?",
    options: ["Transparency", "Accountability", "Privacy", "Fairness"],
    answer: [2],
    explanation: "Privacy is the ethical principle concerned with control over personal data."
  },
  {
    question: "What is 'automation bias'?",
    options: [
      "The tendency to distrust automated systems",
      "The preference for human over machine decisions",
      "The tendency to over-rely on automated systems",
      "The bias introduced by human oversight"
    ],
    answer: [2],
    explanation: "Automation bias is the tendency to favor suggestions from automated systems over human judgment."
  },
  {
    question: "Which of the following is a risk of using facial recognition in public surveillance?",
    options: [
      "Increased computational cost",
      "Reduced battery life of devices",
      "Violation of civil liberties",
      "Improved image resolution"
    ],
    answer: [2],
    explanation: "Facial recognition can infringe on privacy and civil liberties, especially without consent."
  },
  {
    question: "What does 'value alignment' in AI refer to?",
    options: [
      "Ensuring AI systems are profitable",
      "Ensuring AI systems reflect human ethical values",
      "Ensuring AI systems are fast and efficient",
      "Ensuring AI systems are compatible with each other"
    ],
    answer: [1],
    explanation: "Value alignment ensures AI systems act in ways consistent with human values."
  },
  {
    question: "Which of the following is a key concern in using AI for predictive policing?",
    options: [
      "Increased response time",
      "Bias reinforcement",
      "Lack of GPS accuracy",
      "High energy consumption"
    ],
    answer: [1],
    explanation: "Predictive policing can reinforce existing biases in law enforcement data."
  },
  {
    question: "Which term describes AI systems that adapt in ways not anticipated by their designers?",
    options: ["Emergent behavior", "Overfitting", "Bias drift", "Data leakage"],
    answer: [0],
    explanation: "Emergent behavior refers to unexpected actions or strategies developed by AI systems."
  },
  {
    question: "What is the ethical issue with 'deepfakes'?",
    options: [
      "They are expensive to produce",
      "They require high-resolution cameras",
      "They can be used to spread misinformation",
      "They are limited to entertainment use"
    ],
    answer: [2],
    explanation: "Deepfakes can be used maliciously to deceive and manipulate public opinion."
  },
  {
    question: "Which principle is violated when AI systems discriminate based on race or gender?",
    options: ["Transparency", "Justice", "Efficiency", "Autonomy"],
    answer: [1],
    explanation: "Discrimination violates the principle of justice, which demands fairness."
  },
  {
    question: "What is 'data poisoning' in the context of AI ethics?",
    options: [
      "Feeding AI systems with corrupted or malicious data",
      "Using outdated data for training",
      "Encrypting training data",
      "Overloading AI systems with too much data"
    ],
    answer: [0],
    explanation: "Data poisoning involves intentionally corrupting training data to manipulate AI behavior."
  },
  {
    question: "Which of the following is a challenge in ensuring AI accountability?",
    options: [
      "AI systems are too slow",
      "AI systems are always open-source",
      "Responsibility is often diffused among many actors",
      "AI systems are always accurate"
    ],
    answer: [2],
    explanation: "Accountability is difficult when many stakeholders are involved in AI development and deployment."
  },
  {
    question: "Which of the following best defines 'explainability' in AI?",
    options: [
      "The ability of AI to generate reports",
      "The ability to understand and interpret AI decisions",
      "The ability of AI to learn from mistakes",
      "The ability of AI to translate languages"
    ],
    answer: [1],
    explanation: "Explainability refers to how well humans can understand AI decisions."
  },
  {
    question: "Which ethical concern arises when AI replaces human jobs?",
    options: ["Autonomy", "Justice", "Employment displacement", "Transparency"],
    answer: [2],
    explanation: "AI-driven automation can lead to job loss and economic disruption."
  },
  {
    question: "What is the 'alignment problem' in AI?",
    options: [
      "Aligning AI with hardware",
      "Aligning AI with user interfaces",
      "Aligning AI goals with human values",
      "Aligning AI with cloud services"
    ],
    answer: [2],
    explanation: "The alignment problem is about ensuring AI goals match human intentions."
  },
  {
    question: "Which of the following is a risk of using AI in healthcare?",
    options: [
      "Improved diagnostics",
      "Bias in training data leading to unequal treatment",
      "Faster patient intake",
      "Better record-keeping"
    ],
    answer: [1],
    explanation: "Bias in healthcare data can lead to unequal or harmful treatment recommendations."
  },
  {
    question: "Which principle is most relevant when AI systems make decisions that affect human rights?",
    options: ["Efficiency", "Autonomy", "Profitability", "Scalability"],
    answer: [1],
    explanation: "Autonomy is key when decisions impact individuals' rights and freedoms."
  },
  {
    question: "What is 'model inversion' in AI privacy?",
    options: [
      "Reversing a model’s predictions",
      "Reconstructing training data from a model’s outputs",
      "Flipping the model’s weights",
      "Encrypting model parameters"
    ],
    answer: [1],
    explanation: "Model inversion attacks can reveal sensitive data used in training."
  },
  {
    question: "Which of the following is a limitation of AI ethics frameworks?",
    options: [
      "They are legally binding",
      "They are universally accepted",
      "They often lack enforcement mechanisms",
      "They are based on outdated technology"
    ],
    answer: [2],
    explanation: "Ethics frameworks often lack legal or institutional enforcement."
  },
  {
    question: "Which of the following is a concern with AI-generated content?",
    options: [
      "It is always copyrighted",
      "It cannot be edited",
      "It may spread misinformation",
      "It is too expensive to produce"
    ],
    answer: [2],
    explanation: "AI-generated content can be used to spread false or misleading information."
  },
  {
    question: "Which of the following is a challenge in regulating AI globally?",
    options: [
      "AI is not used internationally",
      "There is no interest in AI regulation",
      "Different countries have different legal and ethical standards",
      "AI systems are too simple"
    ],
    answer: [2],
    explanation: "Global regulation is difficult due to differing national laws and values."
  },
  {
    question: "What is 'surveillance capitalism'?",
    options: [
      "Using AI to monitor factory output",
      "Capitalism based on surveillance of workers",
      "Monetizing personal data through surveillance",
      "Government-run surveillance programs"
    ],
    answer: [2],
    explanation: "Surveillance capitalism refers to profiting from personal data collected through surveillance."
  },
  {
    question: "Which of the following is a risk of emotion recognition AI?",
    options: [
      "It improves customer service",
      "It can misinterpret cultural expressions",
      "It reduces bias",
      "It increases transparency"
    ],
    answer: [1],
    explanation: "Emotion recognition can misread expressions, especially across cultures."
  },
  {
    question: "Which of the following best describes 'function creep' in AI?",
    options: [
      "AI systems becoming slower over time",
      "AI systems being used for unintended purposes",
      "AI systems failing to update",
      "AI systems losing accuracy"
    ],
    answer: [1],
    explanation: "Function creep occurs when AI is used beyond its original scope, often without oversight."
  },
    ];

const quizContainer=document.getElementById('quiz-container');
questionsData.forEach((q,index)=>{
  const div=document.createElement('div');
  div.className='quiz-question';
  div.innerHTML=`
    <h3>${index+1}. ${q.question}</h3>
    <ul class="options">
      ${q.options.map((opt,i)=>`<li><button data-index="${i}">${opt}</button></li>`).join('')}
    </ul>
    <div class="explanation"></div>
  `;
  quizContainer.appendChild(div);
});

document.querySelectorAll('.quiz-question').forEach((qEl,qIndex)=>{
  qEl.querySelectorAll('button').forEach(btn=>{
    btn.addEventListener('click',()=>{
      const selected=parseInt(btn.dataset.index);
      const exp=qEl.querySelector('.explanation');
      exp.style.display='block';
      exp.textContent=questionsData[qIndex].explanation;
      qEl.querySelectorAll('button').forEach(b=>b.classList.remove('correct','incorrect'));
      if(questionsData[qIndex].answer.includes(selected))btn.classList.add('correct');
      else btn.classList.add('incorrect');
    });
  });
});

(function(){
  const t=document.getElementById('theme-toggle');
  const key='theme';
  function apply(th){
    if(th==='dark'){document.body.classList.add('dark');t.textContent='Light Mode';}
    else{document.body.classList.remove('dark');t.textContent='Dark Mode';}
  }
  const saved=localStorage.getItem(key)||(window.matchMedia('(prefers-color-scheme: dark)').matches?'dark':'light');
  apply(saved);
  t.addEventListener('click',()=>{
    const n=document.body.classList.contains('dark')?'light':'dark';
    apply(n);
    localStorage.setItem(key,n);
  });
})();
</script>

</body>
</html>
